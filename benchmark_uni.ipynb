{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  StableDiffusionUniPipeline\n",
    "### Prepare\n",
    "\n",
    "```bash\n",
    "# 1. Install diffusers\n",
    "pip install diffusers==0.20.2\n",
    "\n",
    "# 2. Move .py to diffusers install path\n",
    "mv pipeline_stable_diffusion_uni.py xxx/diffusers/pipelines/stable_diffusion/\n",
    "mv pipeline_stable_diffusion_uni_parallel.py xxx/diffusers/pipelines/stable_diffusion/\n",
    "\n",
    "## 3. Edit __init__.py\n",
    "vim xxx/diffusers/pipelines/stable_diffusion/__init__.py\n",
    "#line:210 + StableDiffusionUniPipeline\n",
    "#line:211 + StableDiffusionUniParallelPipeline\n",
    "\n",
    "vim xxx/diffusers/pipelines/stable_diffusion/pipelines/__init__.py\n",
    "#line:110 + StableDiffusionUniPipeline\n",
    "#line:111 + StableDiffusionUniParallelPipeline\n",
    "\n",
    "vim xxx/diffusers/pipelines/stable_diffusion/pipelines/stable_diffusion/__init__.py\n",
    "#line64 + from .pipeline_stable_diffusion_uni import StableDiffusionUniPipeline\n",
    "#line64 + from .pipeline_stable_diffusion_uni_parallel import StableDiffusionUniParallelPipeline\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze|grep diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model_path = 'runwayml/stable-diffusion-v1-5'\n",
    "\n",
    "prompt = [\"a photograph of an astronaut riding a horse\"]\n",
    "height = 512                        # default height of Stable Diffusion\n",
    "width = 512                         # default width of Stable Diffusion\n",
    "num_inference_steps = 20            # Number of denoising steps\n",
    "guidance_scale = 7.5                # Scale for classifier-free guidance\n",
    "generator = torch.manual_seed(32)   # Seed generator to create the inital latent noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### case1: 原txt2img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_path)\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    height=height,\n",
    "    width=width,\n",
    "    generator=generator,\n",
    "    num_inference_steps=num_inference_steps,\n",
    "    guidance_scale=guidance_scale,\n",
    "    ).images[0]\n",
    "\n",
    "image.save(f\"case1.png\")\n",
    "\n",
    "del pipe\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### case2: 原img2img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from diffusers import StableDiffusionImg2ImgPipeline\n",
    "pipe = StableDiffusionImg2ImgPipeline.from_pretrained(model_path)\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "img = Image.open(\"case1.png\")\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    generator=generator,\n",
    "    num_inference_steps=num_inference_steps,\n",
    "    guidance_scale=guidance_scale,\n",
    "    image=img\n",
    "    ).images[0]\n",
    "\n",
    "image.save(f\"case2.png\")\n",
    "\n",
    "del pipe\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### case3: 合并txt2img和img2img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from diffusers import StableDiffusionUniPipeline\n",
    "pipe = StableDiffusionUniPipeline.from_pretrained(model_path)\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "image = pipe(prompt).images[0]\n",
    "image.save(f\"case3_1.png\")\n",
    "\n",
    "del pipe\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "img = Image.open(\"case3_1.png\")\n",
    "image = pipe(prompt, img).images[0]\n",
    "image.save(f\"case3_2.png\")\n",
    "\n",
    "del pipe\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### case4：合并txt2img和img2img，同时CFG并行计算加速\n",
    "StableDiffusionUniParallelPipeline类准备工作同上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from diffusers import StableDiffusionUniParallelPipeline\n",
    "pipe = StableDiffusionUniParallelPipeline.from_pretrained(model_path, single_gpu_parallel=False)\n",
    "\n",
    "image = pipe(prompt).images[0]\n",
    "image.save(f\"case4_1.png\")\n",
    "\n",
    "del pipe\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "img = Image.open(\"case4_1.png\")\n",
    "image = pipe(prompt, img).images[0]\n",
    "image.save(f\"case4_2.png\")\n",
    "\n",
    "del pipe\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BenchMark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/stablediffusion/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model_path = 'runwayml/stable-diffusion-v1-5'\n",
    "prompt = [\"a photograph of an astronaut riding a horse\"]\n",
    "num_inference_steps = 20\n",
    "\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from diffusers import StableDiffusionUniPipeline\n",
    "from diffusers import StableDiffusionUniParallelPipeline\n",
    "\n",
    "# Function execution time statistics（decorator）\n",
    "def timer(f):\n",
    "    import time\n",
    "    def inner(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        result = f(*args, **kwargs)\n",
    "        end = time.time()\n",
    "        print(f\"==> time: {round(end-start, 3)}s\")\n",
    "        return result\n",
    "    return inner\n",
    "\n",
    "@timer\n",
    "def benchmark(pipe, prompt, num_inference_steps):\n",
    "    image = pipe(prompt, num_inference_steps=num_inference_steps).images[0]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'dtype': torch.float16} are not expected by StableDiffusionPipeline and will be ignored.\n",
      "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00, 31.17it/s]\n",
      "100%|██████████| 20/20 [00:06<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> time: 6.839s\n"
     ]
    }
   ],
   "source": [
    "pipe = StableDiffusionPipeline.from_pretrained(model_path, dtype=torch.float16).to(\"cuda\")\n",
    "frame = benchmark(pipe, prompt, num_inference_steps)\n",
    "\n",
    "del pipe\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'dtype': torch.float16} are not expected by StableDiffusionUniPipeline and will be ignored.\n",
      "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00, 31.55it/s]\n",
      "100%|██████████| 20/20 [00:06<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> time: 6.869s\n"
     ]
    }
   ],
   "source": [
    "pipe = StableDiffusionUniPipeline.from_pretrained(model_path, dtype=torch.float16).to(\"cuda\")\n",
    "frame = benchmark(pipe, prompt, num_inference_steps)\n",
    "\n",
    "del pipe\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_encoders: [device(type='cuda', index=0), device(type='cuda', index=0)]\n",
      "unets: [device(type='cuda', index=0), device(type='cuda', index=0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:03<00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> time: 3.483s\n"
     ]
    }
   ],
   "source": [
    "pipe = StableDiffusionUniParallelPipeline.from_pretrained(model_path, single_gpu_parallel=True) #单卡CFG并行\n",
    "frame = benchmark(pipe, prompt, num_inference_steps)\n",
    "\n",
    "del pipe\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_encoders: [device(type='cuda', index=0), device(type='cuda', index=1)]\n",
      "unets: [device(type='cuda', index=0), device(type='cuda', index=1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 12.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> time: 1.828s\n"
     ]
    }
   ],
   "source": [
    "pipe = StableDiffusionUniParallelPipeline.from_pretrained(model_path, single_gpu_parallel=False) #双卡CFG并行\n",
    "frame = benchmark(pipe, prompt, num_inference_steps)\n",
    "\n",
    "del pipe\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
